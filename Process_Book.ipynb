{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Music Magic - CS109 Final Project"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Overview:\n",
      "\n",
      "Music production is expensive and often producers would like to know if a song will do well before they agree to record it. Is there a way to establish such a metric? We will look at popular music from the past 5 years, analyzing songs both in terms of their musical quality and lyrical quality as well as factors like popularity, artists involved in the recording and how they are related, how much the song has been shared, and how many people it has reached, etc.\n",
      "\n",
      "\n",
      "### Motivation:\n",
      "We hope to be able to determine what musical qualities lead to a higher artist rating.\n",
      "\n",
      "\n",
      "We were looking to learn more about:\n",
      "\n",
      "* Music composition \n",
      "* How people\u2019s musical preferences may have changed over time\n",
      "* Properly selecting variables that are relevant\n",
      "* Different types of multivariable models (especially regression models) \n",
      "* Different types of classifiers\n",
      "* Making a judgement regarding what explains the data better\n",
      "* Visualizations, especially those we have not used in homeworks\n",
      "* The big question of what makes a song popular\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Related Work\n",
      "\n",
      "Anything that inspired you, such as a paper, a web site, or something we discussed in class.\n",
      "\n",
      "* [Link](http://www.hooktheory.com/blog/i-analyzed-the-chords-of-1300-popular-songs-for-patterns-this-is-what-i-found/). Another introspection into which musical qualities make for a popular song (not quite that since he doesn't compare it to the musical qualities for non-popular songs, neighter is the way he handles data very scientific, but he does have a lot of specific knowledge about music so this was very interesting for us since we thought to combine parts of what he did with non-musical aspects of music to try to make a prediction for artists.\n",
      "\n",
      "* [Link](http://www.gapminder.org/world/#$majorMode=chart$is;shi=t;ly=2003;lb=f;il=t;fs=11;al=30;stl=t;st=t;nsl=t;se=t$wst;tts=C$ts;sp=5.59290322580644;ti=2012$zpv;v=0$inc_x;mmid=XCOORDS;iid=phAwcNAVuyj1jiMAkmq1iMg;by=ind$inc_y;mmid=YCOORDS;iid=phAwcNAVuyj2tPLxKvvnNPA;by=ind$inc_s;uniValue=8.21;iid=phAwcNAVuyj0XOoBL_n5tAQ;by=ind$inc_c;uniValue=255;gid=CATID0;by=grp$map_x;scale=log;dataMin=283;dataMax=110808$map_y;scale=lin;dataMin=18;dataMax=87$map_s;sma=49;smi=2.65$cd;bd=0$inds=;modified=75).Visualization of change over time, that in our opinion was very successful in demonstrating many pieces of information without cluttering. We first saw it shown in a tech talk and thought it would be perfect for the data we are working with: [Here]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Initial Questions\n",
      "\n",
      "What questions are you trying to answer? How did these questions evolve over the course of the project? What new questions did you consider in the course of your analysis?\n",
      "\n",
      "Initially our questions were skewed heavily towards songs, with most of our questions leading up to one big one: what makes for a successful song? Another example of a question we were excited to answer is: Given Taylor Swift's new album, which song will be the most successful? However, the vast abundancy of data that we looking upon as a great advantange also turned out to be  disadvantage. It is surely impossiblet to use all of it and a lot of the datasets differered vastly in the subset of music that they contained information for. A large part of the process become trying to match up one dataset with another and end up with sometime non-sparse. For our initial analysis of the data, for example, in a frame of 10,000 rows, dropping all rows with either a 0 or a NA value led to a completely empty dataframe!\n",
      "\n",
      "Additionally, a large part of our analysis relied on having ratings for each song. Even after getting permissioned to obtain Yahoo's R2 dataset that contained the most complete information, we struggled to come up with how to match yahoo's song ids to the ids we have already obtained (since no mapping was provided) and dynamically parse through a 5GB dataset, matching it almost to a 2GB dataset. To overcome the issue of sparcity and inability to obtain the proper data on a per-song basis, we altered our original question to focus on the artist -- what kind of general music characteristics make for a higher rated artist?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Data scraping method, cleanup, etc.\n",
      "\n",
      "The majority of the data we used for this project was obtained from Amamzon's Million Song Dataset, Yahoo Labs, and scraped from (ALEX INSERT LINK HERE). Let's get started with obtaining the data:\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Download the \"Million Song Subset\" from...\n",
      "http://static.echonest.com/millionsongsubset_full.tar.gz\n",
      "\n",
      "\n",
      "Extract and place the \"MillionSongSubset\" directory inside your git repo directory (which should be named \"Music_Magic\")\n",
      "\n",
      "Add your basepath below (top of the next cell).\n",
      "\n",
      "My full path to the subset is '/Users/csmiles/Dropbox/Classes/Statistics 121/Music_magic/MillionSongSubset'\n",
      "So my basepath is '/Users/csmiles/Dropbox/Classes/Statistics 121'\n",
      "\n",
      "Comment out the basepaths that aren't yours.\n",
      "\n",
      "Run the code below and start playing around! The code is taken from a tutorial on the Million Song Dataset website, \n",
      "and should give you a good sense of how to use the Python wrapper they provide (it's in the directory \n",
      "                                                                                '/Music_Magic/MSongsDB/PythonSrc', which I pushed to the repository so you don't need to download it manually). There's examples of how to iterate over all the songs, how to use the \"Additional Files\" (which include SQL databases for quick lookups), etc. Still read over the information about the Million Song Subset on the website if you have time though.\n",
      "\n",
      "#### One last thing: \n",
      "\n",
      "I also tried to push a .gitignore file which should've been added to your 'Music_Magic' repo when you pulled. It's really important to have this, otherwise we might accidentally push the entire Million Song Subset (which is still pretty huge) to the repo. If for some reason you don't get the .gitignore file when you pull, maybe try to download it manually from GitHub (it's also only one line, so you could write it yourself) before you commit and push any changes. Remember that it's a hidden file so it won't appear in the regular file browser!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Instructions on how to set up:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SET YOUR BASEPATH\n",
      "#basepath = '/Users/csmiles/Dropbox/Classes/Statistics 121' # Chris\n",
      "basepath = '/Users/anastasiyaborys/Desktop/cs109/Final_Project' # Anastasiya\n",
      "\n",
      "# imports\n",
      "import os\n",
      "import sys\n",
      "import time\n",
      "import glob\n",
      "import datetime\n",
      "import sqlite3\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "from pylab import *\n",
      "import scipy as sp\n",
      "from scipy import stats\n",
      "from matplotlib import rcParams\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "ext='.h5'\n",
      "pd.set_option('display.width', 500)\n",
      "pd.set_option('display.max_columns', 30)\n",
      "\n",
      "# path to the Million Song Dataset subset\n",
      "msd_subset_path = basepath + '/Music_Magic/MillionSongSubset'\n",
      "msd_subset_data_path = os.path.join(msd_subset_path, 'data')\n",
      "msd_subset_addf_path = os.path.join(msd_subset_path, 'AdditionalFiles')\n",
      "assert os.path.isdir(msd_subset_path), 'wrong path'\n",
      "\n",
      "# path to the Million Song Dataset code\n",
      "msd_code_path = basepath + '/Music_Magic/MSongsDB'\n",
      "assert os.path.isdir(msd_code_path), 'wrong path' \n",
      "\n",
      "# we add some paths to python so we can import MSD code\n",
      "sys.path.append(os.path.join(msd_code_path, 'PythonSrc'))\n",
      "\n",
      "# imports specific to the MSD\n",
      "import hdf5_getters as GETTERS\n",
      "\n",
      "# the following function simply gives us a nice string for\n",
      "# a time lag in seconds\n",
      "def strtimedelta(starttime,stoptime):\n",
      "    return str(datetime.timedelta(seconds=stoptime-starttime))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AssertionError",
       "evalue": "wrong path",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-6-8af47dbf5da1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# path to the Million Song Dataset code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mmsd_code_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasepath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/Music_Magic/MSongsDB'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsd_code_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wrong path'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# we add some paths to python so we can import MSD code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAssertionError\u001b[0m: wrong path"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# remove border helper we have been using all along\n",
      "\n",
      "#these colors come from colorbrewer2.org. Each is an RGB triplet\n",
      "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
      "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
      "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),\n",
      "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
      "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
      "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
      "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843),\n",
      "                (0.4, 0.4, 0.4)]\n",
      "\n",
      "rcParams['figure.figsize'] = (10, 6)\n",
      "rcParams['figure.dpi'] = 150\n",
      "rcParams['axes.color_cycle'] = dark2_colors\n",
      "rcParams['lines.linewidth'] = 2\n",
      "rcParams['axes.grid'] = False\n",
      "rcParams['axes.facecolor'] = 'white'\n",
      "rcParams['font.size'] = 14\n",
      "rcParams['patch.edgecolor'] = 'none'\n",
      "\n",
      "\n",
      "def remove_border(axes=None, top=False, right=False, left=True, bottom=True):\n",
      "    \"\"\"\n",
      "    Minimize chartjunk by stripping out unnecessary plot borders and axis ticks\n",
      "    \n",
      "    The top/right/left/bottom keywords toggle whether the corresponding plot border is drawn\n",
      "    \"\"\"\n",
      "    ax = axes or plt.gca()\n",
      "    ax.spines['top'].set_visible(top)\n",
      "    ax.spines['right'].set_visible(right)\n",
      "    ax.spines['left'].set_visible(left)\n",
      "    ax.spines['bottom'].set_visible(bottom)\n",
      "    \n",
      "    #turn off all ticks\n",
      "    ax.yaxis.set_ticks_position('none')\n",
      "    ax.xaxis.set_ticks_position('none')\n",
      "    \n",
      "    #now re-enable visibles\n",
      "    if top:\n",
      "        ax.xaxis.tick_top()\n",
      "    if bottom:\n",
      "        ax.xaxis.tick_bottom()\n",
      "    if left:\n",
      "        ax.yaxis.tick_left()\n",
      "    if right:\n",
      "        ax.yaxis.tick_right()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have a subset of 10,000 songs so let's build a dataframe with the information we want:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_df = pd.DataFrame(columns=('Song_ID', 'Artist_ID', 'Title','Song_Hotness','Danceability', 'Duration', 'Loudness', 'Year', \n",
      "                                'Analysis_Sample_Rate','Song_Energy', 'Album_Name', 'Bars_Confidence', 'Key', 'Mode',\n",
      "                                'Mode_confidence', 'Tempo', 'Artist_Name', 'Artist_location', 'Artist_Hotness', 'Similar_Artists',\n",
      "                                'Artist_Tags'))\n",
      "print 'Dataframe created with the following rows:' , data_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "basedir = msd_subset_data_path\n",
      "for root, dirs, files in os.walk(basedir):\n",
      "    files = glob.glob(os.path.join(root,'*'+ext))\n",
      "    for f in files :\n",
      "            \n",
      "        h5 = GETTERS.open_h5_file_read(f) \n",
      "    \n",
      "        # song information\n",
      "        song_id = GETTERS.get_song_id(h5) \n",
      "        song_title = GETTERS.get_title(h5)\n",
      "        song_hotness = GETTERS.get_song_hotttnesss(h5)\n",
      "        song_dancability = GETTERS.get_danceability(h5)\n",
      "        song_duration = GETTERS.get_duration(h5)\n",
      "        song_loudness = GETTERS.get_loudness(h5)\n",
      "        song_year = GETTERS.get_year(h5)\n",
      "        analysis_sample_rate = GETTERS.get_analysis_sample_rate(h5)\n",
      "        energy = GETTERS.get_energy(h5)\n",
      "        bars_confidence = GETTERS.get_bars_confidence(h5)\n",
      "        key = GETTERS.get_key(h5)\n",
      "        mode = GETTERS.get_mode(h5)\n",
      "        mode_confidence = GETTERS.get_mode_confidence(h5)\n",
      "        tempo = GETTERS.get_tempo(h5)\n",
      "           \n",
      "        # artist information\n",
      "        album_name = GETTERS.get_release(h5)\n",
      "        artist_id = GETTERS.get_artist_id(h5)\n",
      "        artist_name = GETTERS.get_artist_name(h5)\n",
      "        artist_location = GETTERS.get_artist_location(h5)\n",
      "        artist_hotness = GETTERS.get_artist_hotttnesss(h5)\n",
      "        similar_artists = GETTERS.get_similar_artists(h5)\n",
      "        artist_tags = GETTERS.get_artist_mbtags(h5)\n",
      "    \n",
      "            \n",
      "        data_df = data_df.append([dict(Song_ID = song_id, Artist_ID = artist_id, Title=song_title, \n",
      "                                       Song_Hotness=song_hotness, Danceability=song_dancability, \n",
      "                                       Duration=song_duration, Loudness=song_loudness, Year=song_year,\n",
      "                                       Album_Name = album_name, Bars_Confidence = bars_confidence,\n",
      "                                       Mode = mode, Key = key,\n",
      "                                       Mode_confidence = mode_confidence, Tempo = tempo,\n",
      "                                       Analysis_Sample_Rate = analysis_sample_rate, Song_Energy = energy,\n",
      "                                       Artist_Name=artist_name, Artist_location=artist_location, \n",
      "                                       Artist_Hotness=artist_hotness, Similar_Artists=similar_artists,\n",
      "                                       Artist_Tags=artist_tags)], ignore_index=True)\n",
      "        h5.close()      \n",
      "   \n",
      "print \"Done\"\n",
      "print data_df\n",
      "# so that we don't have to keep rerunning the code\n",
      "data_df.to_csv('all_data.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate the data we need from the yahoo dataset\n",
      "# Chris please put in more description about what you're doing here\n",
      "name_aid_dict = {}\n",
      "\n",
      "f = open(basepath + '/Music_Magic/YahooR1/output.txt','r')\n",
      "for line in f.xreadlines():\n",
      "    parts = line.strip().split('<SEP>')\n",
      "    name_aid_dict[parts[0]] = parts[1]\n",
      "f.close()\n",
      "\n",
      "yid_name_dict = {}\n",
      "\n",
      "f = open(basepath + '/Music_Magic/YahooR1/ydata-ymusic-artist-names-v1_0.txt','r')\n",
      "for line in f.xreadlines():\n",
      "    parts = line.strip().split('\\t')\n",
      "    yid_name_dict[parts[0]] = parts[1]\n",
      "f.close()\n",
      "\n",
      "aids, names, yids, ratings, uids = [],[],[],[],[]\n",
      "\n",
      "# read yahoo data\n",
      "f = open(basepath + '/Music_Magic/YahooR1/ydata-ymusic-user-artist-ratings-v1_0.txt','r')\n",
      "for line in f.xreadlines():\n",
      "    parts = line.strip().split('\\t')\n",
      "    yid = parts[1]\n",
      "    if yid in yid_name_dict:\n",
      "        name = yid_name_dict[yid]\n",
      "        if name in name_aid_dict:\n",
      "            aid = name_aid_dict[name]\n",
      "            aids.append(aid)\n",
      "            names.append(name)\n",
      "            yids.append(yid)\n",
      "            ratings.append(parts[2])\n",
      "            uids.append(parts[0])\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "yahoo_dataframe = pd.DataFrame({'aids': aids, 'names': names, 'yids': yids, 'ratings': ratings, 'uids': uids})\n",
      "yahoo_dataframe.to_csv('yahoo_ratings.csv', index = False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load both dataframes in\n",
      "data_df = pd.read_csv(\"all_data.csv\")\n",
      "yahoo_dataframe = pd.read_csv(\"yahoo_ratings.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Song_ID</th>\n",
        "      <th>Artist_ID</th>\n",
        "      <th>Title</th>\n",
        "      <th>Song_Hotness</th>\n",
        "      <th>Danceability</th>\n",
        "      <th>Duration</th>\n",
        "      <th>Loudness</th>\n",
        "      <th>Year</th>\n",
        "      <th>Analysis_Sample_Rate</th>\n",
        "      <th>Song_Energy</th>\n",
        "      <th>Album_Name</th>\n",
        "      <th>Bars_Confidence</th>\n",
        "      <th>Key</th>\n",
        "      <th>Mode</th>\n",
        "      <th>Mode_confidence</th>\n",
        "      <th>Tempo</th>\n",
        "      <th>Artist_Name</th>\n",
        "      <th>Artist_location</th>\n",
        "      <th>Artist_Hotness</th>\n",
        "      <th>Similar_Artists</th>\n",
        "      <th>Artist_Tags</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> SOMZWCG12A8C13C480</td>\n",
        "      <td> ARD7TVE1187B99BFB1</td>\n",
        "      <td> I Didn't Mean To</td>\n",
        "      <td> 0.602120</td>\n",
        "      <td> 0</td>\n",
        "      <td> 218.93179</td>\n",
        "      <td>-11.197</td>\n",
        "      <td>    0</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 0</td>\n",
        "      <td>                         Fear Itself</td>\n",
        "      <td> [ 0.643  0.746  0.722  0.095  0.091  0.362  0....</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.636</td>\n",
        "      <td>  92.198</td>\n",
        "      <td>           Casual</td>\n",
        "      <td> California - LA</td>\n",
        "      <td> 0.401998</td>\n",
        "      <td> ['ARV4KO21187FB38008' 'ARWHM281187FB3D381' 'AR...</td>\n",
        "      <td>                         []</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> SOCIWDW12A8C13D406</td>\n",
        "      <td> ARMJAGH1187FB546F3</td>\n",
        "      <td>        Soul Deep</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 148.03546</td>\n",
        "      <td> -9.843</td>\n",
        "      <td> 1969</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 0</td>\n",
        "      <td>                          Dimensions</td>\n",
        "      <td> [ 0.007  0.259  0.172  0.404  0.011  0.016  0....</td>\n",
        "      <td> 6</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.430</td>\n",
        "      <td> 121.274</td>\n",
        "      <td>     The Box Tops</td>\n",
        "      <td>     Memphis, TN</td>\n",
        "      <td> 0.417500</td>\n",
        "      <td> ['ARSZWK21187B9B26D7' 'ARLDW2Y1187B9B544F' 'AR...</td>\n",
        "      <td>   ['classic pop and rock']</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> SOXVLOJ12AB0189215</td>\n",
        "      <td> ARKRRTF1187B9984DA</td>\n",
        "      <td>  Amor De Cabaret</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 177.47546</td>\n",
        "      <td> -9.689</td>\n",
        "      <td>    0</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 0</td>\n",
        "      <td> Las Numero 1 De La Sonora Santanera</td>\n",
        "      <td> [ 0.98   0.399  0.185  0.27   0.422  0.     0....</td>\n",
        "      <td> 8</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.565</td>\n",
        "      <td> 100.070</td>\n",
        "      <td> Sonora Santanera</td>\n",
        "      <td>             NaN</td>\n",
        "      <td> 0.343428</td>\n",
        "      <td> ['ARFSJUG11C8A421AAD' 'AR8SD041187FB36015' 'AR...</td>\n",
        "      <td>                         []</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> SONHOTT12A8C13493C</td>\n",
        "      <td> AR7G5I41187FB4CE6C</td>\n",
        "      <td>  Something Girls</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 233.40363</td>\n",
        "      <td> -9.013</td>\n",
        "      <td> 1982</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 0</td>\n",
        "      <td>                       Friend Or Foe</td>\n",
        "      <td> [ 0.017  0.05   0.014  0.008  0.114  0.019  0....</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.749</td>\n",
        "      <td> 119.293</td>\n",
        "      <td>         Adam Ant</td>\n",
        "      <td> London, England</td>\n",
        "      <td> 0.454231</td>\n",
        "      <td> ['AR4R0741187FB39AF2' 'AR0D7K21187B9AD14E' 'AR...</td>\n",
        "      <td> ['uk' 'british' 'english']</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> SOFSOCN12A8C143F5D</td>\n",
        "      <td> ARXR32B1187FB57099</td>\n",
        "      <td>   Face the Ashes</td>\n",
        "      <td> 0.604501</td>\n",
        "      <td> 0</td>\n",
        "      <td> 209.60608</td>\n",
        "      <td> -4.501</td>\n",
        "      <td> 2007</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 0</td>\n",
        "      <td>                       Muertos Vivos</td>\n",
        "      <td> [ 0.175  0.409  0.639  0.067  0.016  0.066  0....</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.371</td>\n",
        "      <td> 129.738</td>\n",
        "      <td>              Gob</td>\n",
        "      <td>             NaN</td>\n",
        "      <td> 0.401724</td>\n",
        "      <td> ['ARUA62A1187B99D9B0' 'ARHJFFY1187B98BA76' 'AR...</td>\n",
        "      <td>                         []</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "              Song_ID           Artist_ID             Title  Song_Hotness  Danceability   Duration  Loudness  Year  Analysis_Sample_Rate  Song_Energy                           Album_Name                                    Bars_Confidence  Key  Mode  Mode_confidence    Tempo       Artist_Name  Artist_location  Artist_Hotness                                    Similar_Artists                 Artist_Tags\n",
        "0  SOMZWCG12A8C13C480  ARD7TVE1187B99BFB1  I Didn't Mean To      0.602120             0  218.93179   -11.197     0                 22050            0                          Fear Itself  [ 0.643  0.746  0.722  0.095  0.091  0.362  0....    1     0            0.636   92.198            Casual  California - LA        0.401998  ['ARV4KO21187FB38008' 'ARWHM281187FB3D381' 'AR...                          []\n",
        "1  SOCIWDW12A8C13D406  ARMJAGH1187FB546F3         Soul Deep           NaN             0  148.03546    -9.843  1969                 22050            0                           Dimensions  [ 0.007  0.259  0.172  0.404  0.011  0.016  0....    6     0            0.430  121.274      The Box Tops      Memphis, TN        0.417500  ['ARSZWK21187B9B26D7' 'ARLDW2Y1187B9B544F' 'AR...    ['classic pop and rock']\n",
        "2  SOXVLOJ12AB0189215  ARKRRTF1187B9984DA   Amor De Cabaret           NaN             0  177.47546    -9.689     0                 22050            0  Las Numero 1 De La Sonora Santanera  [ 0.98   0.399  0.185  0.27   0.422  0.     0....    8     1            0.565  100.070  Sonora Santanera              NaN        0.343428  ['ARFSJUG11C8A421AAD' 'AR8SD041187FB36015' 'AR...                          []\n",
        "3  SONHOTT12A8C13493C  AR7G5I41187FB4CE6C   Something Girls           NaN             0  233.40363    -9.013  1982                 22050            0                        Friend Or Foe  [ 0.017  0.05   0.014  0.008  0.114  0.019  0....    0     1            0.749  119.293          Adam Ant  London, England        0.454231  ['AR4R0741187FB39AF2' 'AR0D7K21187B9AD14E' 'AR...  ['uk' 'british' 'english']\n",
        "4  SOFSOCN12A8C143F5D  ARXR32B1187FB57099    Face the Ashes      0.604501             0  209.60608    -4.501  2007                 22050            0                        Muertos Vivos  [ 0.175  0.409  0.639  0.067  0.016  0.066  0....    2     1            0.371  129.738               Gob              NaN        0.401724  ['ARUA62A1187B99D9B0' 'ARHJFFY1187B98BA76' 'AR...                          []"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "yahoo_dataframe.set_index(['aids'], inplace=True)\n",
      "yahoo_dataframe.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>names</th>\n",
        "      <th>ratings</th>\n",
        "      <th>uids</th>\n",
        "      <th>yids</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>aids</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>ARXSABJ1187FB3C336</th>\n",
        "      <td>        Deftones</td>\n",
        "      <td>  90</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1006978</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ARMBTFC1187FB56343</th>\n",
        "      <td>            Korn</td>\n",
        "      <td> 100</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1014635</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ART5MUE1187B98C961</th>\n",
        "      <td>       Metallica</td>\n",
        "      <td> 100</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1017874</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ARK9TRQ1187B99C095</th>\n",
        "      <td> Nine Inch Nails</td>\n",
        "      <td> 100</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1019512</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ARH3S5S1187FB4F76B</th>\n",
        "      <td>         Nirvana</td>\n",
        "      <td> 100</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1019522</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "                              names  ratings  uids     yids\n",
        "aids                                                       \n",
        "ARXSABJ1187FB3C336         Deftones       90     1  1006978\n",
        "ARMBTFC1187FB56343             Korn      100     1  1014635\n",
        "ART5MUE1187B98C961        Metallica      100     1  1017874\n",
        "ARK9TRQ1187B99C095  Nine Inch Nails      100     1  1019512\n",
        "ARH3S5S1187FB4F76B          Nirvana      100     1  1019522"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Unique songs: \", len(data_df.Song_ID.unique())\n",
      "print \"Unique artists: \", len(data_df.Artist_ID.unique())\n",
      "\n",
      "\n",
      "### compute some category averages\n",
      "def recompute_frame(ldf):\n",
      "  \n",
      "    ### can do it by artist and by album\n",
      "    ldfu=ldf.groupby('Artist_ID')\n",
      " \n",
      "    nldf=ldf.copy()\n",
      "    nldf.set_index(['Artist_ID'], inplace=True)\n",
      "   \n",
      "    nldf['Artist_Song_count'] = ldfu.Song_ID.count()\n",
      "    nldf['Artist_avg_song_hotness'] = ldfu.Song_Hotness.mean()\n",
      "    nldf['Artist_avg_dancibility'] = ldfu.Danceability.mean()\n",
      "    nldf['Artist_avg_duration'] = ldfu.Duration.mean()\n",
      "    nldf['Artist_avg_loudness'] = ldfu.Loudness.mean()\n",
      "    nldf['Artist_avg_release'] = ldfu.Year.mean()\n",
      "    nldf['Artist_avg_analysis_sample_rate'] = ldfu.Analysis_Sample_Rate.mean()\n",
      "    nldf['Artist_avg_key'] = ldfu.Key.mean()\n",
      "    nldf['Artist_avg_tempo'] = ldfu.Tempo.mean()\n",
      "    #### could always add more category averages here\n",
      "    \n",
      " #   nldf.reset_index(inplace=True)\n",
      "    return nldf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Unique songs:  10000\n",
        "Unique artists:  3888\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_frame = recompute_frame(data_df)\n",
      "print \"Still contains information on a per-song basis: \", len(new_frame.index)\n",
      "### TODO want to aggregate information here in order not to throw it out\n",
      "### make sure that title and song id are aggreagated, etc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Still contains information on a per-song basis:  10000\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_frame = new_frame.drop_duplicates(cols='index',take_last=True) ## TODO make sure to do this correctly\n",
      "print \"Now all the duplicate indices have been removed: \", len(new_frame.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "u'no item named index'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-63-245920453c52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtake_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## TODO make sure to do this correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Now all the duplicate indices have been removed: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/anastasiyaborys/anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mdrop_duplicates\u001b[0;34m(self, cols, take_last, inplace)\u001b[0m\n\u001b[1;32m   3118\u001b[0m         \"\"\"\n\u001b[1;32m   3119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3120\u001b[0;31m         \u001b[0mduplicated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtake_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtake_last\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/anastasiyaborys/anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mduplicated\u001b[0;34m(self, cols, take_last)\u001b[0m\n\u001b[1;32m   3162\u001b[0m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_m8_to_i8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3163\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3164\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3166\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_zip_fillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/anastasiyaborys/anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2001\u001b[0m             \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2002\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2003\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2005\u001b[0m             \u001b[0;31m# duplicate columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/anastasiyaborys/anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/anastasiyaborys/anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1653\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/anastasiyaborys/anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_find_block\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_find_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1935\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_have\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1936\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/anastasiyaborys/anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_check_have\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_have\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1942\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no item named %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint_thing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1944\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyError\u001b[0m: u'no item named index'"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# drop some of the columns it doesn't have make sense to have anymore\n",
      "#new_frame = new_frame.drop('Song_Hotness',1)\n",
      "#new_frame = new_frame.drop('Danceability',1)\n",
      "#### TODO drop the rest of the meaningless categories here ...\n",
      "\n",
      "new_frame.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Song_ID</th>\n",
        "      <th>Title</th>\n",
        "      <th>Duration</th>\n",
        "      <th>Loudness</th>\n",
        "      <th>Year</th>\n",
        "      <th>Analysis_Sample_Rate</th>\n",
        "      <th>Song_Energy</th>\n",
        "      <th>Album_Name</th>\n",
        "      <th>Bars_Confidence</th>\n",
        "      <th>Key</th>\n",
        "      <th>Mode</th>\n",
        "      <th>Mode_confidence</th>\n",
        "      <th>Tempo</th>\n",
        "      <th>Artist_Name</th>\n",
        "      <th>Artist_location</th>\n",
        "      <th>Artist_Hotness</th>\n",
        "      <th>Similar_Artists</th>\n",
        "      <th>Artist_Tags</th>\n",
        "      <th>Artist_Song_count</th>\n",
        "      <th>Artist_avg_song_hotness</th>\n",
        "      <th>Artist_avg_dancibility</th>\n",
        "      <th>Artist_avg_duration</th>\n",
        "      <th>Artist_avg_loudness</th>\n",
        "      <th>Artist_avg_release</th>\n",
        "      <th>Artist_avg_analysis_sample_rate</th>\n",
        "      <th>Artist_avg_key</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Artist_ID</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>ARD7TVE1187B99BFB1</th>\n",
        "      <td> SOMZWCG12A8C13C480</td>\n",
        "      <td> I Didn't Mean To</td>\n",
        "      <td> 218.93179</td>\n",
        "      <td>-11.197</td>\n",
        "      <td>    0</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 0</td>\n",
        "      <td>                         Fear Itself</td>\n",
        "      <td> [ 0.643  0.746  0.722  0.095  0.091  0.362  0....</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.636</td>\n",
        "      <td>  92.198</td>\n",
        "      <td>           Casual</td>\n",
        "      <td> California - LA</td>\n",
        "      <td> 0.401998</td>\n",
        "      <td> ['ARV4KO21187FB38008' 'ARWHM281187FB3D381' 'AR...</td>\n",
        "      <td>                         []</td>\n",
        "      <td> 8</td>\n",
        "      <td> 0.161977</td>\n",
        "      <td> 0</td>\n",
        "      <td> 222.445261</td>\n",
        "      <td> -8.589875</td>\n",
        "      <td>  251.00</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 4.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ARMJAGH1187FB546F3</th>\n",
        "      <td> SOCIWDW12A8C13D406</td>\n",
        "      <td>        Soul Deep</td>\n",
        "      <td> 148.03546</td>\n",
        "      <td> -9.843</td>\n",
        "      <td> 1969</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 0</td>\n",
        "      <td>                          Dimensions</td>\n",
        "      <td> [ 0.007  0.259  0.172  0.404  0.011  0.016  0....</td>\n",
        "      <td> 6</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.430</td>\n",
        "      <td> 121.274</td>\n",
        "      <td>     The Box Tops</td>\n",
        "      <td>     Memphis, TN</td>\n",
        "      <td> 0.417500</td>\n",
        "      <td> ['ARSZWK21187B9B26D7' 'ARLDW2Y1187B9B544F' 'AR...</td>\n",
        "      <td>   ['classic pop and rock']</td>\n",
        "      <td> 4</td>\n",
        "      <td> 0.413740</td>\n",
        "      <td> 0</td>\n",
        "      <td> 154.102402</td>\n",
        "      <td>-11.062500</td>\n",
        "      <td> 1967.75</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 4.25</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ARKRRTF1187B9984DA</th>\n",
        "      <td> SOXVLOJ12AB0189215</td>\n",
        "      <td>  Amor De Cabaret</td>\n",
        "      <td> 177.47546</td>\n",
        "      <td> -9.689</td>\n",
        "      <td>    0</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 0</td>\n",
        "      <td> Las Numero 1 De La Sonora Santanera</td>\n",
        "      <td> [ 0.98   0.399  0.185  0.27   0.422  0.     0....</td>\n",
        "      <td> 8</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.565</td>\n",
        "      <td> 100.070</td>\n",
        "      <td> Sonora Santanera</td>\n",
        "      <td>             NaN</td>\n",
        "      <td> 0.343428</td>\n",
        "      <td> ['ARFSJUG11C8A421AAD' 'AR8SD041187FB36015' 'AR...</td>\n",
        "      <td>                         []</td>\n",
        "      <td> 4</td>\n",
        "      <td> 0.484563</td>\n",
        "      <td> 0</td>\n",
        "      <td> 166.092608</td>\n",
        "      <td>-11.321250</td>\n",
        "      <td>  500.75</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 3.00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AR7G5I41187FB4CE6C</th>\n",
        "      <td> SONHOTT12A8C13493C</td>\n",
        "      <td>  Something Girls</td>\n",
        "      <td> 233.40363</td>\n",
        "      <td> -9.013</td>\n",
        "      <td> 1982</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 0</td>\n",
        "      <td>                       Friend Or Foe</td>\n",
        "      <td> [ 0.017  0.05   0.014  0.008  0.114  0.019  0....</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.749</td>\n",
        "      <td> 119.293</td>\n",
        "      <td>         Adam Ant</td>\n",
        "      <td> London, England</td>\n",
        "      <td> 0.454231</td>\n",
        "      <td> ['AR4R0741187FB39AF2' 'AR0D7K21187B9AD14E' 'AR...</td>\n",
        "      <td> ['uk' 'british' 'english']</td>\n",
        "      <td> 5</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 214.067792</td>\n",
        "      <td> -8.476800</td>\n",
        "      <td> 1588.80</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 3.80</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ARXR32B1187FB57099</th>\n",
        "      <td> SOFSOCN12A8C143F5D</td>\n",
        "      <td>   Face the Ashes</td>\n",
        "      <td> 209.60608</td>\n",
        "      <td> -4.501</td>\n",
        "      <td> 2007</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 0</td>\n",
        "      <td>                       Muertos Vivos</td>\n",
        "      <td> [ 0.175  0.409  0.639  0.067  0.016  0.066  0....</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.371</td>\n",
        "      <td> 129.738</td>\n",
        "      <td>              Gob</td>\n",
        "      <td>             NaN</td>\n",
        "      <td> 0.401724</td>\n",
        "      <td> ['ARUA62A1187B99D9B0' 'ARHJFFY1187B98BA76' 'AR...</td>\n",
        "      <td>                         []</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0.631352</td>\n",
        "      <td> 0</td>\n",
        "      <td> 181.472200</td>\n",
        "      <td> -5.210500</td>\n",
        "      <td> 2004.00</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 3.00</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "                               Song_ID             Title   Duration  Loudness  Year  Analysis_Sample_Rate  Song_Energy                           Album_Name                                    Bars_Confidence  Key  Mode  Mode_confidence    Tempo       Artist_Name  Artist_location  Artist_Hotness                                    Similar_Artists                 Artist_Tags  Artist_Song_count  Artist_avg_song_hotness  Artist_avg_dancibility  Artist_avg_duration  Artist_avg_loudness  \\\n",
        "Artist_ID                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
        "ARD7TVE1187B99BFB1  SOMZWCG12A8C13C480  I Didn't Mean To  218.93179   -11.197     0                 22050            0                          Fear Itself  [ 0.643  0.746  0.722  0.095  0.091  0.362  0....    1     0            0.636   92.198            Casual  California - LA        0.401998  ['ARV4KO21187FB38008' 'ARWHM281187FB3D381' 'AR...                          []                  8                 0.161977                       0           222.445261            -8.589875   \n",
        "ARMJAGH1187FB546F3  SOCIWDW12A8C13D406         Soul Deep  148.03546    -9.843  1969                 22050            0                           Dimensions  [ 0.007  0.259  0.172  0.404  0.011  0.016  0....    6     0            0.430  121.274      The Box Tops      Memphis, TN        0.417500  ['ARSZWK21187B9B26D7' 'ARLDW2Y1187B9B544F' 'AR...    ['classic pop and rock']                  4                 0.413740                       0           154.102402           -11.062500   \n",
        "ARKRRTF1187B9984DA  SOXVLOJ12AB0189215   Amor De Cabaret  177.47546    -9.689     0                 22050            0  Las Numero 1 De La Sonora Santanera  [ 0.98   0.399  0.185  0.27   0.422  0.     0....    8     1            0.565  100.070  Sonora Santanera              NaN        0.343428  ['ARFSJUG11C8A421AAD' 'AR8SD041187FB36015' 'AR...                          []                  4                 0.484563                       0           166.092608           -11.321250   \n",
        "AR7G5I41187FB4CE6C  SONHOTT12A8C13493C   Something Girls  233.40363    -9.013  1982                 22050            0                        Friend Or Foe  [ 0.017  0.05   0.014  0.008  0.114  0.019  0....    0     1            0.749  119.293          Adam Ant  London, England        0.454231  ['AR4R0741187FB39AF2' 'AR0D7K21187B9AD14E' 'AR...  ['uk' 'british' 'english']                  5                      NaN                       0           214.067792            -8.476800   \n",
        "ARXR32B1187FB57099  SOFSOCN12A8C143F5D    Face the Ashes  209.60608    -4.501  2007                 22050            0                        Muertos Vivos  [ 0.175  0.409  0.639  0.067  0.016  0.066  0....    2     1            0.371  129.738               Gob              NaN        0.401724  ['ARUA62A1187B99D9B0' 'ARHJFFY1187B98BA76' 'AR...                          []                  2                 0.631352                       0           181.472200            -5.210500   \n",
        "\n",
        "                    Artist_avg_release  Artist_avg_analysis_sample_rate  Artist_avg_key  \n",
        "Artist_ID                                                                                \n",
        "ARD7TVE1187B99BFB1              251.00                            22050            4.50  \n",
        "ARMJAGH1187FB546F3             1967.75                            22050            4.25  \n",
        "ARKRRTF1187B9984DA              500.75                            22050            3.00  \n",
        "AR7G5I41187FB4CE6C             1588.80                            22050            3.80  \n",
        "ARXR32B1187FB57099             2004.00                            22050            3.00  "
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now we want to match on artist_ID with the yahoo dataset\n",
      "final_frame = pd.merge(new_frame, yahoo_dataframe, left_index=True, right_index=True)\n",
      "final_frame.head()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_frame.to_csv(\"final_df\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exploratory Analysis:\n",
      "What visualizations did you use to look at your data in different ways? What are the different statistical methods you considered? Justify the decisions you made, and show any major changes to your ideas. How did you reach these conclusions?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load in all the data we just cleaned up\n",
      "final_frame = pd.read_csv(\"final_df.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# connect to the SQLite database\n",
      "conn = sqlite3.connect(os.path.join(msd_subset_addf_path, 'subset_artist_term.db'))\n",
      "\n",
      "# from that connection, get a cursor to do queries\n",
      "c = conn.cursor()\n",
      "\n",
      "# get terms and their counts\n",
      "q = \"SELECT DISTINCT term,Count(artist_id) FROM artist_term\"\n",
      "q += \" GROUP BY term\"\n",
      "res = c.execute(q)\n",
      "terms = res.fetchall()\n",
      "c.close()\n",
      "\n",
      "# most common terms (top 100)\n",
      "most_common_terms = sorted(terms,key=lambda x:x[1],reverse=True)[:100]\n",
      "term_freqs = map(lambda x: x[1], most_common_terms)\n",
      "term_names = map(lambda x: x[0], most_common_terms)\n",
      "\n",
      "# plot\n",
      "plt.figure(figsize = (18,6))\n",
      "plt.bar(np.arange(len(term_freqs)) * 100, term_freqs, align='center', width=50)\n",
      "xlocs = np.arange(len(term_freqs)) * 100\n",
      "xticks_locs, xticks_labels = plt.xticks(xlocs, term_names)\n",
      "plt.setp(xticks_labels, rotation=90, fontsize=8)\n",
      "plt.xlim(min(xlocs) - 100, max(xlocs) + 100)\n",
      "plt.ylabel(\"Number of Artists\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# connect to the SQLite database\n",
      "conn = sqlite3.connect(os.path.join(msd_subset_addf_path, 'subset_track_metadata.db'))\n",
      "\n",
      "# from that connection, get a cursor to do queries\n",
      "c = conn.cursor()\n",
      "\n",
      "# so there is no confusion, the table name is 'songs'\n",
      "TABLENAME = 'songs'\n",
      "\n",
      "# get artists and their hotttnesss / familiarity scores\n",
      "q = \"SELECT artist_id,artist_name,AVG(artist_hotttnesss),AVG(artist_familiarity) FROM songs\"\n",
      "q += \" GROUP BY artist_id\"\n",
      "res = c.execute(q)\n",
      "artists = res.fetchall()\n",
      "\n",
      "sorted_by_hotttnesss = sorted(artists,key=lambda x:x[2],reverse=True)[:100]\n",
      "artist_hotttnesss = map(lambda x: x[2], sorted_by_hotttnesss)\n",
      "artist_names = map(lambda x: x[1], sorted_by_hotttnesss)\n",
      "\n",
      "plt.figure(figsize = (18,6))\n",
      "plt.bar(np.arange(len(artist_hotttnesss)) * 100, artist_hotttnesss, align='center', width=50)\n",
      "xlocs = np.arange(len(artist_hotttnesss)) * 100\n",
      "xticks_locs, xticks_labels = plt.xticks(xlocs, artist_names)\n",
      "plt.setp(xticks_labels, rotation=90, fontsize=8)\n",
      "plt.xlim(min(xlocs) - 100, max(xlocs) + 100)\n",
      "plt.ylabel(\"Hotttnesss\")\n",
      "plt.show()\n",
      "\n",
      "sorted_by_familiarity = sorted(artists,key=lambda x:x[3],reverse=True)[:100]\n",
      "artist_familiarity = map(lambda x: x[3], sorted_by_familiarity)\n",
      "artist_names = map(lambda x: x[1], sorted_by_familiarity)\n",
      "\n",
      "# plot\n",
      "plt.figure(figsize = (18,6))\n",
      "plt.bar(np.arange(len(artist_familiarity)) * 100, artist_familiarity, align='center', width=50)\n",
      "xlocs = np.arange(len(artist_familiarity)) * 100\n",
      "xticks_locs, xticks_labels = plt.xticks(xlocs, artist_names)\n",
      "plt.setp(xticks_labels, rotation=90, fontsize=8)\n",
      "plt.xlim(min(xlocs) - 100, max(xlocs) + 100)\n",
      "plt.ylabel(\"Familiarity\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = final_frame.groupby(\"Year\").mean() ## we probably will not need to groupby anymore\n",
      "#for key, value in test:\n",
      "#    print value[\"Loudness\"]\n",
      "test.head(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Alex -- instead of rewriting the same code I just made this into a function\n",
      "\n",
      "def plotlineg(data, title=\"\"):\n",
      "    plt.figure(figsize = (18,6))\n",
      "    plt.plot(np.arange(len(data)-1) * 100, data[1:])\n",
      "    xlocs = np.arange(len(data)-1) * 100\n",
      "    xticks_locs, xticks_labels = plt.xticks(xlocs, test.index[1:])\n",
      "    plt.setp(xticks_labels, rotation=90, fontsize=8)\n",
      "    plt.xlim(min(xlocs) - 100, max(xlocs) + 100)\n",
      "    plt.ylabel(title)\n",
      "    remove_border()\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plotlineg(test['Loudness'], \"Average Loudness of Songs\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plotlineg(test['Duration'], \"Average Duration of Songs\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plotlineg(test['Tempo'], \"Average Tempo of Songs\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plotlineg(test['Artist_Hotness'], \"Average Artist Hotness\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def scatter_regress(data1, data2, title=\"\"):\n",
      "    np.polyfit(data1, data2, 2) \n",
      "\n",
      "    plt.scatter(data1, data2)\n",
      "    remove_border()\n",
      "\n",
      "    fit = polyfit(data1, data2,1)\n",
      "    fit_fn = poly1d(fit)\n",
      "    plot(data1,data2, 'yo', data1, fit_fn(data1), '--k')\n",
      "    plt.title(title)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scatter_regress(final_df.Artist_avg_loudness.values, final_df.Artist_avg_duration, \"Loudness vs Duration\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### etc can do virtually any combination"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##### ALEX - PLEASE PUT IN THE JAVASCRIPT STUFF HERE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Build a classifier to see what are the most commonly used lyrics in the songs that we're looking at"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# connect to the SQLite database\n",
      "conn = sqlite3.connect(os.path.join(msd_subset_addf_path, 'subset_track_metadata.db'))\n",
      "\n",
      "# from that connection, get a cursor to do queries\n",
      "c = conn.cursor()\n",
      "\n",
      "# get lyrics from training data\n",
      "q = \"SELECT track_id FROM songs\"\n",
      "res = c.execute(q)\n",
      "subset_tracks = res.fetchall()\n",
      "\n",
      "subset_tracks = map(lambda x: x[0], subset_tracks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# connect to the SQLite database\n",
      "conn = sqlite3.connect(os.path.join(mxm_dataset_path, 'mxm_dataset.db'))\n",
      "\n",
      "# from that connection, get a cursor to do queries\n",
      "c = conn.cursor()\n",
      "\n",
      "# get lyrics from training data\n",
      "q = \"SELECT track_id,word,count FROM lyrics\" # WHERE is_test=0 LIMIT 1000000\n",
      "res = c.execute(q)\n",
      "lyrics = res.fetchall()\n",
      "\n",
      "track_ids = map(lambda x: x[0], lyrics)\n",
      "words = map(lambda x: x[1], lyrics)\n",
      "counts = map(lambda x: x[2], lyrics)\n",
      "\n",
      "lyrics_df = pd.DataFrame({'track_id': track_ids, 'word': words, 'count': counts })\n",
      "grouped_by_track = lyrics_df.groupby('track_id')\n",
      "\n",
      "track_lyrics_list = []\n",
      "for track_id in grouped_by_track.groups:\n",
      "    if track_id in subset_tracks:\n",
      "        track_lyrics = ''\n",
      "        for _, row in lyrics_df[lyrics_df['track_id'] == track_id].iterrows():\n",
      "            for i in xrange(int(row['count'])):\n",
      "                track_lyrics = track_lyrics + \" \" + row['word']\n",
      "        track_lyrics_list.append(track_lyrics)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = CountVectorizer(min_df=3)\n",
      "vectorizer.fit(track_lyrics_list)\n",
      "transformed = vectorizer.transform(track_lyrics_list)\n",
      "# transformed = transformed.toarray()\n",
      "# print vectorizer.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# connect to the SQLite database\n",
      "conn = sqlite3.connect(os.path.join(msd_subset_addf_path, 'subset_track_metadata.db'))\n",
      "\n",
      "# from that connection, get a cursor to do queries\n",
      "c = conn.cursor()\n",
      "\n",
      "subset_track_ids = []\n",
      "subset_artist_ids = []\n",
      "for track_id in grouped_by_track.groups:\n",
      "    if track_id in subset_tracks:\n",
      "        q = \"SELECT artist_id FROM songs WHERE track_id='\"\n",
      "        q += track_id + \"'\"\n",
      "        res = c.execute(q)\n",
      "        artist_id = res.fetchall()\n",
      "        subset_artist_ids.append(artist_id[0][0])\n",
      "        subset_track_ids.append(track_id)\n",
      "        \n",
      "track_artist_tags_df = pd.DataFrame({'track_id': subset_track_ids, 'artist_id': subset_artist_ids})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# connect to the SQLite database\n",
      "conn = sqlite3.connect(os.path.join(msd_subset_addf_path, 'subset_artist_term.db'))\n",
      "\n",
      "# from that connection, get a cursor to do queries\n",
      "c = conn.cursor()\n",
      "\n",
      "top_100_terms = term_names[:100]\n",
      "print top_100_terms\n",
      "\n",
      "for term in top_100_terms:\n",
      "    term_counts = []\n",
      "    for _, row in track_artist_tags_df.iterrows():\n",
      "        q = \"SELECT COUNT(*) FROM artist_term\"\n",
      "        q += \" WHERE term='\" + term + \"'\"\n",
      "        q += \" AND artist_id='\" + row['artist_id'] + \"'\"\n",
      "        res = c.execute(q)\n",
      "        term_count = res.fetchall()\n",
      "        term_counts.append(term_count[0][0])\n",
      "    track_artist_tags_df[term] = term_counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_term = 'christian'\n",
      "\n",
      "X = np.array(transformed.toarray())\n",
      "Y = np.array(track_artist_tags_df[test_term])\n",
      "\n",
      "# split the data into groups\n",
      "xtrain, xtest, ytrain, ytest = train_test_split(X, Y)\n",
      "# make and train the new NB classifier\n",
      "clf = MultinomialNB()\n",
      "clf.fit(xtrain, ytrain)\n",
      "\n",
      "# print the accuracy for the test data\n",
      "test_acc = clf.score(xtest, ytest)\n",
      "# print the accuracy for the training data\n",
      "train_acc = clf.score(xtrain, ytrain)\n",
      "\n",
      "print \"Accuracy on training data is\", train_acc\n",
      "print \"Accuracy on test data is\", test_acc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# grab the words\n",
      "features = vectorizer.get_feature_names()\n",
      "# create a matrix representing one quote/word\n",
      "# (where the entire quote is simply the word)\n",
      "probs = clf.predict_proba(np.eye(len(features)))\n",
      "\n",
      "# sort and get the 10 words with the highest prob_fresh\n",
      "print \"10 most \" + test_term + \" words:\"\n",
      "for i in probs[:,1].argsort()[-10:]:\n",
      "    print features[i]\n",
      "    \n",
      "print \"\\n\"\n",
      "\n",
      "# sort and get the 10 words with the highest prob_rotten\n",
      "print \"10 least \" + test_term + \" words:\"\n",
      "for i in probs[:,0].argsort()[-10:]:\n",
      "    print features[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us identify which variables are significant using the Spearman coefficient as well as looking at thier correlation with ratings. Here is a little bit about it, which speaks to why we decided to use it:\n",
      "The Spearman correlation is a nonparametric measure of the linear relationship between two datasets. Unlike the Pearson correlation, the Spearman correlation does not assume that both datasets are normally distributed. Like other correlation coefficients, this one varies between -1 and +1 with 0 implying no correlation. Correlations of -1 or +1 imply an exact linear relationship. Positive correlations imply that as x increases, so does y. Negative correlations imply that as x increases, y decreases.\n",
      "\n",
      "The p-value roughly indicates the probability of an uncorrelated system producing datasets that have a Spearman correlation at least as extreme as the one computed from these datasets. The p-values are not entirely reliable but are probably reasonable for datasets larger than 500 or so."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scatter_regress(final_df.Ratings.values, final_df.Artist_hotness.values, \"Ratings and Artist Hotness\") \n",
      "print \"Relationship between ratings and artist hotness: \", stats.spearmanr(final_df.Ratings.values, final_df.Artist_Hotness)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### do this for all other variables we consider explanatory"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After examining this information, we can see that variables that are explanatory are: ## FILL IN\n",
      "\n",
      "Let's try building a few linear multivariate models to and see how well each does in predicting the rating for our data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ols\n",
      "from numpy.random import randn\n",
      "data = randn(100,5)\n",
      "y = data[:,0]\n",
      "x = data[:,1:]\n",
      "mymodel = ols.ols(y,x,'y',['x1','x2','x3','x4'])\n",
      "print mymodel.p               # return coefficient p-values\n",
      "\n",
      "mymodel.summary()  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### information on the rest of the models is available here:\n",
      "# http://scikit-learn.org/stable/modules/linear_model.html#bayesian-regression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Summary:\n",
      "    \n",
      "    ################### HUGE"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "*css tweaks in this cell*\n",
      "<style>\n",
      "div.text_cell_render {\n",
      "    line-height: 150%;\n",
      "    font-size: 110%;\n",
      "    width: 800px;\n",
      "    margin-left:50px;\n",
      "    margin-right:auto;\n",
      "    }\n",
      "</style>\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}