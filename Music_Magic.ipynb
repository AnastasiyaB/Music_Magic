{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Music Magic - CS109 Final Project"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Overview and Motivation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Related Work"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Initial Questions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Data\n",
      "\n",
      "First, we get our data from the Million Song Dataset.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Instructions on how to set up:\n",
      "\n",
      "Download the \"Million Song Subset\" from...\n",
      "http://static.echonest.com/millionsongsubset_full.tar.gz\n",
      "\n",
      "\n",
      "Extract and place the \"MillionSongSubset\" directory inside your git repo directory (which should be named \"Music_Magic\")\n",
      "\n",
      "\n",
      "Add your basepath below (top of the next cell).\n",
      "\n",
      "My full path to the subset is '/Users/csmiles/Dropbox/Classes/Statistics 121/Music_magic/MillionSongSubset'\n",
      "So my basepath is '/Users/csmiles/Dropbox/Classes/Statistics 121'\n",
      "\n",
      "Comment out the basepaths that aren't yours.\n",
      "\n",
      "Run the code below and start playing around! The code is taken from a tutorial on the Million Song Dataset website, and should give you a good sense of how to use the Python wrapper they provide (it's in the directory '/Music_Magic/MSongsDB/PythonSrc', which I pushed to the repository so you don't need to download it manually). There's examples of how to iterate over all the songs, how to use the \"Additional Files\" (which include SQL databases for quick lookups), etc. Still read over the information about the Million Song Subset on the website if you have time though.\n",
      "\n",
      "#### One last thing: \n",
      "\n",
      "I also tried to push a .gitignore file which should've been added to your 'Music_Magic' repo when you pulled. It's really important to have this, otherwise we might accidentally push the entire Million Song Subset (which is still pretty huge) to the repo. If for some reason you don't get the .gitignore file when you pull, maybe try to download it manually from GitHub (it's also only one line, so you could write it yourself) before you commit and push any changes. Remember that it's a hidden file so it won't appear in the regular file browser!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SET YOUR BASEPATH\n",
      "# uncomment as necessary\n",
      "\n",
      "basepath = '/Users/csmiles/Dropbox/Classes/Statistics 121' # Chris\n",
      "# basepath = '' # Anastasiya\n",
      "# basepath = '' # Alex\n",
      "\n",
      "# usual imports\n",
      "import os\n",
      "import sys\n",
      "import time\n",
      "import glob\n",
      "import datetime\n",
      "import sqlite3\n",
      "import numpy as np\n",
      "\n",
      "# path to the Million Song Dataset subset\n",
      "msd_subset_path = basepath + '/Music_Magic/MillionSongSubset'\n",
      "msd_subset_data_path = os.path.join(msd_subset_path, 'data')\n",
      "msd_subset_addf_path = os.path.join(msd_subset_path, 'AdditionalFiles')\n",
      "assert os.path.isdir(msd_subset_path), 'wrong path' # sanity check\n",
      "\n",
      "# path to the Million Song Dataset code\n",
      "msd_code_path = basepath + '/Music_Magic/MSongsDB'\n",
      "assert os.path.isdir(msd_code_path), 'wrong path' # sanity check\n",
      "\n",
      "# we add some paths to python so we can import MSD code\n",
      "sys.path.append(os.path.join(msd_code_path, 'PythonSrc'))\n",
      "\n",
      "# imports specific to the MSD\n",
      "import hdf5_getters as GETTERS\n",
      "\n",
      "# the following function simply gives us a nice string for\n",
      "# a time lag in seconds\n",
      "def strtimedelta(starttime,stoptime):\n",
      "    return str(datetime.timedelta(seconds=stoptime-starttime))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# we define this very useful function to iterate the files\n",
      "def apply_to_all_files(basedir,func=lambda x: x,ext='.h5'):\n",
      "    \"\"\"\n",
      "    From a base directory, go through all subdirectories,\n",
      "    find all files with the given extension, apply the\n",
      "    given function 'func' to all of them.\n",
      "    If no 'func' is passed, we do nothing except counting.\n",
      "    INPUT\n",
      "       basedir  - base directory of the dataset\n",
      "       func     - function to apply to all filenames\n",
      "       ext      - extension, .h5 by default\n",
      "    RETURN\n",
      "       number of files\n",
      "    \"\"\"\n",
      "    cnt = 0\n",
      "    # iterate over all files in all subdirectories\n",
      "    for root, dirs, files in os.walk(basedir):\n",
      "        files = glob.glob(os.path.join(root,'*'+ext))\n",
      "        # count files\n",
      "        cnt += len(files)\n",
      "        # apply function to all files\n",
      "        for f in files :\n",
      "            func(f)       \n",
      "    return cnt\n",
      "\n",
      "\n",
      "# we can now easily count the number of files in the dataset\n",
      "print 'number of song files:',apply_to_all_files(msd_subset_data_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of song files: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7432\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's now get all artist names in a set(). One nice property:\n",
      "# if we enter many times the same artist, only one will be kept.\n",
      "all_artist_names = set()\n",
      "\n",
      "# we define the function to apply to all files\n",
      "def func_to_get_artist_name(filename):\n",
      "    \"\"\"\n",
      "    This function does 3 simple things:\n",
      "    - open the song file\n",
      "    - get artist ID and put it\n",
      "    - close the file\n",
      "    \"\"\"\n",
      "    h5 = GETTERS.open_h5_file_read(filename)\n",
      "    artist_name = GETTERS.get_artist_name(h5)\n",
      "    all_artist_names.add( artist_name )\n",
      "    h5.close()\n",
      "    \n",
      "# let's apply the previous function to all files\n",
      "# we'll also measure how long it takes\n",
      "t1 = time.time()\n",
      "apply_to_all_files(msd_subset_data_path,func=func_to_get_artist_name)\n",
      "t2 = time.time()\n",
      "print 'all artist names extracted in:',strtimedelta(t1,t2)\n",
      "\n",
      "# let's see some of the content of 'all_artist_names'\n",
      "print 'found',len(all_artist_names),'unique artist names'\n",
      "for k in range(5):\n",
      "    print list(all_artist_names)[k]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "all artist names extracted in: 0:00:47.325899\n",
        "found 3731 unique artist names\n",
        "Groundhogs\n",
        "Pale Forest\n",
        "The Real Kids\n",
        "JennyAnyKind\n",
        "Spooky Tooth / Mike Harrison\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this is too long, and the work of listing artist names has already\n",
      "# been done. Let's redo the same task using an SQLite database.\n",
      "# We connect to the provided database: track_metadata.db\n",
      "conn = sqlite3.connect(os.path.join(msd_subset_addf_path,\n",
      "                                    'subset_track_metadata.db'))\n",
      "# we build the SQL query\n",
      "q = \"SELECT DISTINCT artist_name FROM songs\"\n",
      "# we query the database\n",
      "t1 = time.time()\n",
      "res = conn.execute(q)\n",
      "all_artist_names_sqlite = res.fetchall()\n",
      "t2 = time.time()\n",
      "print 'all artist names extracted (SQLite) in:',strtimedelta(t1,t2)\n",
      "# we close the connection to the database\n",
      "conn.close()\n",
      "# let's see some of the content\n",
      "for k in range(5):\n",
      "    print all_artist_names_sqlite[k][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "all artist names extracted (SQLite) in: 0:00:00.013644\n",
        "!!!\n",
        "(hed) p.e.\n",
        "089 Clique feat. Minnesota Snipe & Skinny Cueball\n",
        "089 Clique feat. Prophet\n",
        "1. Futurologischer Congress\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now, let's find the artist that has the most songs in the dataset\n",
      "# what we want to work with is artist ID, not artist names. Some artists\n",
      "# have many names, usually because the song is \"featuring someone else\"\n",
      "conn = sqlite3.connect(os.path.join(msd_subset_addf_path,\n",
      "                                    'subset_track_metadata.db'))\n",
      "q = \"SELECT DISTINCT artist_id FROM songs\"\n",
      "res = conn.execute(q)\n",
      "all_artist_ids = map(lambda x: x[0], res.fetchall())\n",
      "conn.close()\n",
      "\n",
      "# The Echo Nest artist id look like:\n",
      "for k in range(4):\n",
      "    print all_artist_ids[k]\n",
      "    \n",
      "# let's count the songs from each of these artists.\n",
      "# We will do it first by iterating over the dataset.\n",
      "# we prepare a dictionary to count files\n",
      "files_per_artist = {}\n",
      "for aid in all_artist_ids:\n",
      "    files_per_artist[aid] = 0\n",
      "\n",
      "# we prepare the function to check artist id in each file\n",
      "def func_to_count_artist_id(filename):\n",
      "    \"\"\"\n",
      "    This function does 3 simple things:\n",
      "    - open the song file\n",
      "    - get artist ID and put it\n",
      "    - close the file\n",
      "    \"\"\"\n",
      "    h5 = GETTERS.open_h5_file_read(filename)\n",
      "    artist_id = GETTERS.get_artist_id(h5)\n",
      "    files_per_artist[artist_id] += 1\n",
      "    h5.close()\n",
      "\n",
      "# we apply this function to all files\n",
      "apply_to_all_files(msd_subset_data_path,func=func_to_count_artist_id)\n",
      "\n",
      "# the most popular artist (with the most songs) is:\n",
      "most_pop_aid = sorted(files_per_artist,\n",
      "                      key=files_per_artist.__getitem__,\n",
      "                      reverse=True)[0]\n",
      "print most_pop_aid,'has',files_per_artist[most_pop_aid],'songs.'\n",
      "\n",
      "# of course, it is more fun to have the name(s) of this artist\n",
      "# let's get it using SQLite\n",
      "conn = sqlite3.connect(os.path.join(msd_subset_addf_path,\n",
      "                                    'subset_track_metadata.db'))\n",
      "q = \"SELECT DISTINCT artist_name FROM songs\"\n",
      "q += \" WHERE artist_id='\"+most_pop_aid+\"'\"\n",
      "res = conn.execute(q)\n",
      "pop_artist_names = map(lambda x: x[0], res.fetchall())\n",
      "conn.close()\n",
      "print 'SQL query:',q\n",
      "print 'name(s) of the most popular artist:',pop_artist_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AR009211187B989185\n",
        "AR00A6H1187FB5402A\n",
        "AR00LNI1187FB444A5\n",
        "AR00MBZ1187B9B5DB1\n",
        "AR12F2S1187FB56EEF"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has 12 songs.\n",
        "SQL query: SELECT DISTINCT artist_name FROM songs WHERE artist_id='AR12F2S1187FB56EEF'\n",
        "name(s) of the most popular artist: [u'Aerosmith']\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's redo all this work in SQLite in a few seconds\n",
      "t1 = time.time()\n",
      "conn = sqlite3.connect(os.path.join(msd_subset_addf_path,\n",
      "                                    'subset_track_metadata.db'))\n",
      "q = \"SELECT DISTINCT artist_id,artist_name,Count(track_id) FROM songs\"\n",
      "q += \" GROUP BY artist_id\"\n",
      "res = conn.execute(q)\n",
      "pop_artists = res.fetchall()\n",
      "conn.close()\n",
      "t2 = time.time()\n",
      "print 'found most popular artist in',strtimedelta(t1,t2)\n",
      "print sorted(pop_artists,key=lambda x:x[2],reverse=True)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "found most popular artist in 0:00:00.065831\n",
        "(u'AROIHOI122988FEB8E', u'Mario Rosenstock', 13)\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "*css tweaks in this cell*\n",
      "<style>\n",
      "div.text_cell_render {\n",
      "    line-height: 150%;\n",
      "    font-size: 110%;\n",
      "    width: 800px;\n",
      "    margin-left:50px;\n",
      "    margin-right:auto;\n",
      "    }\n",
      "</style>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}