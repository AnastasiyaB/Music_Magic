{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Music Magic - CS109 Final Project"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Overview and Motivation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Related Work"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Initial Questions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Data\n",
      "\n",
      "First, we get our data from the Million Song Dataset.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Instructions on how to set up:\n",
      "\n",
      "Download the \"Million Song Subset\" from...\n",
      "http://static.echonest.com/millionsongsubset_full.tar.gz\n",
      "\n",
      "\n",
      "Extract and place the \"MillionSongSubset\" directory inside your git repo directory (which should be named \"Music_Magic\")\n",
      "\n",
      "\n",
      "Add your basepath below (top of the next cell).\n",
      "\n",
      "My full path to the subset is '/Users/csmiles/Dropbox/Classes/Statistics 121/Music_magic/MillionSongSubset'\n",
      "So my basepath is '/Users/csmiles/Dropbox/Classes/Statistics 121'\n",
      "\n",
      "Comment out the basepaths that aren't yours.\n",
      "\n",
      "Run the code below and start playing around! The code is taken from a tutorial on the Million Song Dataset website, and should give you a good sense of how to use the Python wrapper they provide (it's in the directory '/Music_Magic/MSongsDB/PythonSrc', which I pushed to the repository so you don't need to download it manually). There's examples of how to iterate over all the songs, how to use the \"Additional Files\" (which include SQL databases for quick lookups), etc. Still read over the information about the Million Song Subset on the website if you have time though.\n",
      "\n",
      "#### One last thing: \n",
      "\n",
      "I also tried to push a .gitignore file which should've been added to your 'Music_Magic' repo when you pulled. It's really important to have this, otherwise we might accidentally push the entire Million Song Subset (which is still pretty huge) to the repo. If for some reason you don't get the .gitignore file when you pull, maybe try to download it manually from GitHub (it's also only one line, so you could write it yourself) before you commit and push any changes. Remember that it's a hidden file so it won't appear in the regular file browser!\n",
      "\n",
      "\n",
      "Note: these are all the fields available to us: http://labrosa.ee.columbia.edu/millionsong/pages/field-list"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SET YOUR BASEPATH\n",
      "# uncomment as necessary\n",
      "\n",
      "#basepath = '/Users/csmiles/Dropbox/Classes/Statistics 121' # Chris\n",
      "basepath = '/Users/anastasiyaborys/Desktop/cs109/Final_Project' # Anastasiya\n",
      "# basepath = '' # Alex\n",
      "\n",
      "# usual imports\n",
      "import os\n",
      "import sys\n",
      "import time\n",
      "import glob\n",
      "import datetime\n",
      "import sqlite3\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "from pylab import *\n",
      "import scipy as sp\n",
      "from scipy import stats\n",
      "from matplotlib import rcParams\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "ext='.h5'\n",
      "pd.set_option('display.width', 500)\n",
      "pd.set_option('display.max_columns', 30)\n",
      "\n",
      "\n",
      "#these colors come from colorbrewer2.org. Each is an RGB triplet\n",
      "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
      "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
      "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),\n",
      "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
      "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
      "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
      "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843),\n",
      "                (0.4, 0.4, 0.4)]\n",
      "\n",
      "rcParams['figure.figsize'] = (10, 6)\n",
      "rcParams['figure.dpi'] = 150\n",
      "rcParams['axes.color_cycle'] = dark2_colors\n",
      "rcParams['lines.linewidth'] = 2\n",
      "rcParams['axes.grid'] = False\n",
      "rcParams['axes.facecolor'] = 'white'\n",
      "rcParams['font.size'] = 14\n",
      "rcParams['patch.edgecolor'] = 'none'\n",
      "\n",
      "\n",
      "def remove_border(axes=None, top=False, right=False, left=True, bottom=True):\n",
      "    \"\"\"\n",
      "    Minimize chartjunk by stripping out unnecessary plot borders and axis ticks\n",
      "    \n",
      "    The top/right/left/bottom keywords toggle whether the corresponding plot border is drawn\n",
      "    \"\"\"\n",
      "    ax = axes or plt.gca()\n",
      "    ax.spines['top'].set_visible(top)\n",
      "    ax.spines['right'].set_visible(right)\n",
      "    ax.spines['left'].set_visible(left)\n",
      "    ax.spines['bottom'].set_visible(bottom)\n",
      "    \n",
      "    #turn off all ticks\n",
      "    ax.yaxis.set_ticks_position('none')\n",
      "    ax.xaxis.set_ticks_position('none')\n",
      "    \n",
      "    #now re-enable visibles\n",
      "    if top:\n",
      "        ax.xaxis.tick_top()\n",
      "    if bottom:\n",
      "        ax.xaxis.tick_bottom()\n",
      "    if left:\n",
      "        ax.yaxis.tick_left()\n",
      "    if right:\n",
      "        ax.yaxis.tick_right()\n",
      "        \n",
      "# path to the Million Song Dataset subset\n",
      "msd_subset_path = basepath + '/Music_Magic/MillionSongSubset'\n",
      "msd_subset_data_path = os.path.join(msd_subset_path, 'data_real')\n",
      "msd_subset_addf_path = os.path.join(msd_subset_path, 'AdditionalFiles')\n",
      "assert os.path.isdir(msd_subset_path), 'wrong path' # sanity check\n",
      "\n",
      "# path to the Million Song Dataset code\n",
      "msd_code_path = basepath + '/Music_Magic/MSongsDB'\n",
      "#assert os.path.isdir(msd_code_path), 'wrong path' # sanity check\n",
      "\n",
      "# we add some paths to python so we can import MSD code\n",
      "sys.path.append(os.path.join(msd_code_path, 'PythonSrc'))\n",
      "\n",
      "# imports specific to the MSD\n",
      "import hdf5_getters as GETTERS\n",
      "\n",
      "# the following function simply gives us a nice string for\n",
      "# a time lag in seconds\n",
      "def strtimedelta(starttime,stoptime):\n",
      "    return str(datetime.timedelta(seconds=stoptime-starttime))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named hdf5_getters",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-6-9c89666de887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m# imports specific to the MSD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhdf5_getters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mGETTERS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;31m# the following function simply gives us a nice string for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mImportError\u001b[0m: No module named hdf5_getters"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Lets first do some exploratory analysis:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have a subset of 10,000 songs. Let's organize it, clean it up a little, and see what's inside:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_df = pd.DataFrame(columns=('Song_ID', 'Artist_ID', 'Title','Song_Hotness','Danceability',\n",
      "                                'Duration', 'Loudness', 'Year', 'Analysis_Sample_Rate','Song_Energy',\n",
      "                                'Album_Name', 'Bars_Confidence', 'Key', #'Key_Confidence','Beats_Confidence',\n",
      "                                'Mode', 'Mode_confidence', 'Tempo', #'Artist_Familiarity', 'Artist_Terms',\n",
      "                                'Artist_Name', 'Artist_location', 'Artist_Hotness', 'Similar_Artists',\n",
      "                                'Artist_Tags'))\n",
      "print 'dataframe created:' , data_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dataframe created: Empty DataFrame\n",
        "Columns: [Song_ID, Artist_ID, Title, Song_Hotness, Danceability, Duration, Loudness, Year, Analysis_Sample_Rate, Song_Energy, Album_Name, Bars_Confidence, Key, Mode, Mode_confidence, Tempo, Artist_Name, Artist_location, Artist_Hotness, Similar_Artists, Artist_Tags]\n",
        "Index: []\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "basedir = msd_subset_data_path\n",
      "for root, dirs, files in os.walk(basedir):\n",
      "    files = glob.glob(os.path.join(root,'*'+ext))\n",
      "    for f in files :\n",
      "            \n",
      "        h5 = GETTERS.open_h5_file_read(f) \n",
      "    \n",
      "        # song information\n",
      "        song_id = GETTERS.get_song_id(h5) # order the information by song\n",
      "        song_title = GETTERS.get_title(h5)\n",
      "        song_hotness = GETTERS.get_song_hotttnesss(h5)\n",
      "        song_dancability = GETTERS.get_danceability(h5)\n",
      "        song_duration = GETTERS.get_duration(h5)\n",
      "        song_loudness = GETTERS.get_loudness(h5)\n",
      "        song_year = GETTERS.get_year(h5)\n",
      "        analysis_sample_rate = GETTERS.get_analysis_sample_rate(h5)\n",
      "        energy = GETTERS.get_energy(h5)\n",
      "        \n",
      "        #extra\n",
      "        bars_confidence = GETTERS.get_bars_confidence(h5)\n",
      "        beats_confidence = GETTERS.get_beats_confidence(h5)\n",
      "        key = GETTERS.get_key(h5)\n",
      "        key_confidence = GETTERS.get_key_confidence(h5)\n",
      "        mode = GETTERS.get_mode(h5)\n",
      "        mode_confidence = GETTERS.get_mode_confidence(h5)\n",
      "        tempo = GETTERS.get_tempo(h5)\n",
      "           \n",
      "        # artist information\n",
      "        album_name = GETTERS.get_release(h5)\n",
      "        artist_id = GETTERS.get_artist_id(h5)\n",
      "        artist_name = GETTERS.get_artist_name(h5)\n",
      "        artist_location = GETTERS.get_artist_location(h5)\n",
      "        artist_hotness = GETTERS.get_artist_hotttnesss(h5)\n",
      "        similar_artists = GETTERS.get_similar_artists(h5)\n",
      "        artist_tags = GETTERS.get_artist_mbtags(h5)\n",
      "        \n",
      "        #extra\n",
      "        artist_familiarity = GETTERS.get_artist_familiarity(h5)\n",
      "        artist_terms = GETTERS.get_artist_terms(h5)\n",
      "\n",
      "            \n",
      "        data_df = data_df.append([dict(Song_ID = song_id, Artist_ID = artist_id, Title=song_title, \n",
      "                                       Song_Hotness=song_hotness, Danceability=song_dancability, \n",
      "                                       Duration=song_duration, Loudness=song_loudness, Year=song_year,\n",
      "                                       Album_Name = album_name, Bars_Confidence = bars_confidence,\n",
      "                                       #Beats_confidence = beats_confidence, \n",
      "                                       #Key_confidence = key_confidence,\n",
      "                                       Mode = mode, Key = key,\n",
      "                                       Mode_confidence = mode_confidence, Tempo = tempo,\n",
      "                                       #Artist_familiarity = artist_familiarity, Artist_terms = artist_terms,\n",
      "                                       Analysis_Sample_Rate = analysis_sample_rate, Song_Energy = energy,\n",
      "                                       Artist_Name=artist_name, Artist_location=artist_location, \n",
      "                                       Artist_Hotness=artist_hotness, Similar_Artists=similar_artists,\n",
      "                                       Artist_Tags=artist_tags)], ignore_index=True)\n",
      "        h5.close()      \n",
      "   \n",
      "print \"Done\"\n",
      "print data_df\n",
      "data_df.to_csv('all_data.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 626 entries, 0 to 625\n",
        "Data columns (total 21 columns):\n",
        "Song_ID                 626  non-null values\n",
        "Artist_ID               626  non-null values\n",
        "Title                   626  non-null values\n",
        "Song_Hotness            339  non-null values\n",
        "Danceability            626  non-null values\n",
        "Duration                626  non-null values\n",
        "Loudness                626  non-null values\n",
        "Year                    626  non-null values\n",
        "Analysis_Sample_Rate    626  non-null values\n",
        "Song_Energy             626  non-null values\n",
        "Album_Name              626  non-null values\n",
        "Bars_Confidence         626  non-null values\n",
        "Key                     626  non-null values\n",
        "Mode                    626  non-null values\n",
        "Mode_confidence         626  non-null values\n",
        "Tempo                   626  non-null values\n",
        "Artist_Name             626  non-null values\n",
        "Artist_location         626  non-null values\n",
        "Artist_Hotness          626  non-null values\n",
        "Similar_Artists         626  non-null values\n",
        "Artist_Tags             626  non-null values\n",
        "dtypes: float64(8), int64(4), object(9)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# insert a fake column with ratings for now\n",
      "\n",
      "data_df =pd.read_csv(\"all_data.csv\")\n",
      "data_df['Ratings'] = pd.Series(np.random.randint(1,6,len(data_df.Title)), index=data_df.index)\n",
      "data_df.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Song_ID</th>\n",
        "      <th>Artist_ID</th>\n",
        "      <th>Title</th>\n",
        "      <th>Song_Hotness</th>\n",
        "      <th>Danceability</th>\n",
        "      <th>Duration</th>\n",
        "      <th>Loudness</th>\n",
        "      <th>Year</th>\n",
        "      <th>Analysis_Sample_Rate</th>\n",
        "      <th>Song_Energy</th>\n",
        "      <th>Album_Name</th>\n",
        "      <th>Bars_Confidence</th>\n",
        "      <th>Key</th>\n",
        "      <th>Mode</th>\n",
        "      <th>Mode_confidence</th>\n",
        "      <th>Tempo</th>\n",
        "      <th>Artist_Name</th>\n",
        "      <th>Artist_location</th>\n",
        "      <th>Artist_Hotness</th>\n",
        "      <th>Similar_Artists</th>\n",
        "      <th>Artist_Tags</th>\n",
        "      <th>Ratings</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> SOMTZGM12AB0187CA0</td>\n",
        "      <td> AR5K75Y1187B9B5F7E</td>\n",
        "      <td>   Water-Liked</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 226.74240</td>\n",
        "      <td>-10.623</td>\n",
        "      <td>    0</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 0</td>\n",
        "      <td>                         Wish</td>\n",
        "      <td> [ 0.102  0.065  0.113  0.137  0.252  0.135  0....</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.658</td>\n",
        "      <td> 116.043</td>\n",
        "      <td>               Janice Vidal</td>\n",
        "      <td>                      NaN</td>\n",
        "      <td> 0.429602</td>\n",
        "      <td> ['ARQ2PMX1187FB38D62' 'ARHNL9K1187FB5730C' 'AR...</td>\n",
        "      <td>    ['mandarin' 'cantonese' 'hong kong' 'chinese']</td>\n",
        "      <td> 5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> SOXJOMM12A6D4F8673</td>\n",
        "      <td> ARF1E421187B9AF8C4</td>\n",
        "      <td> Alma de B-Boy</td>\n",
        "      <td> 0.511424</td>\n",
        "      <td> 0</td>\n",
        "      <td> 208.66567</td>\n",
        "      <td> -7.705</td>\n",
        "      <td>    0</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 0</td>\n",
        "      <td>     Comunicaflow Underground</td>\n",
        "      <td> [ 0.071  0.037  0.056  0.171  0.022  0.048  0....</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.559</td>\n",
        "      <td> 120.064</td>\n",
        "      <td>           El Gran Silencio</td>\n",
        "      <td>                      NaN</td>\n",
        "      <td> 0.375494</td>\n",
        "      <td> ['AR5U53D1187FB37654' 'ARCW1I81187FB41D5D' 'AR...</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> SOJGTKX12AB0188C94</td>\n",
        "      <td> ARQ76LG1187B9ACD84</td>\n",
        "      <td> Jealous Again</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 136.14975</td>\n",
        "      <td> -6.419</td>\n",
        "      <td> 1980</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 0</td>\n",
        "      <td> Live at The On Broadway 1982</td>\n",
        "      <td> [ 0.195  0.169  0.113  0.081  0.187  0.411  0....</td>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.553</td>\n",
        "      <td> 124.481</td>\n",
        "      <td>                 Black Flag</td>\n",
        "      <td>          Los Angeles, CA</td>\n",
        "      <td> 0.547507</td>\n",
        "      <td> ['AR7Y6JX1187FB4D9B3' 'ARCC31M1187B9ACB05' 'AR...</td>\n",
        "      <td> ['hardcore punk' 'california' 'hermosa beach' ...</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> SOSQCCK12AB0186B7C</td>\n",
        "      <td> AR7LN7G1187FB395BB</td>\n",
        "      <td>    \u00c0 Mon Avis</td>\n",
        "      <td> 0.352232</td>\n",
        "      <td> 0</td>\n",
        "      <td> 431.93424</td>\n",
        "      <td> -6.451</td>\n",
        "      <td>    0</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 0</td>\n",
        "      <td>                 Bakolo Mboka</td>\n",
        "      <td> [ 0.099  0.001  0.083  0.021  0.076  0.085  0....</td>\n",
        "      <td> 7</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.131</td>\n",
        "      <td> 134.046</td>\n",
        "      <td> Les Bantous De La Capitale</td>\n",
        "      <td>                      NaN</td>\n",
        "      <td> 0.273366</td>\n",
        "      <td> ['ARXK8H71187FB44850' 'ARNMVXP11F50C4BAFF' 'AR...</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> SOQXTRG12A6D4F898E</td>\n",
        "      <td> AR3N2H11187B98AFBA</td>\n",
        "      <td>       Energia</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 238.00118</td>\n",
        "      <td>-10.623</td>\n",
        "      <td>    0</td>\n",
        "      <td> 22050</td>\n",
        "      <td> 0</td>\n",
        "      <td>              Selecao De Ouro</td>\n",
        "      <td> [ 0.133  0.389  0.205  0.106  0.081  0.172  0....</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.187</td>\n",
        "      <td> 224.247</td>\n",
        "      <td>                     Sivuca</td>\n",
        "      <td> Itabaiana, Para\ufffd, Brazil</td>\n",
        "      <td> 0.324334</td>\n",
        "      <td> ['ARI4RPW1187B9B862D' 'ARQCHDN1187FB4C7C2' 'AR...</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "              Song_ID           Artist_ID          Title  Song_Hotness  Danceability   Duration  Loudness  Year  Analysis_Sample_Rate  Song_Energy                    Album_Name                                    Bars_Confidence  Key  Mode  Mode_confidence    Tempo                 Artist_Name           Artist_location  Artist_Hotness                                    Similar_Artists                                        Artist_Tags  Ratings\n",
        "0  SOMTZGM12AB0187CA0  AR5K75Y1187B9B5F7E    Water-Liked           NaN             0  226.74240   -10.623     0                 22050            0                          Wish  [ 0.102  0.065  0.113  0.137  0.252  0.135  0....    1     1            0.658  116.043                Janice Vidal                       NaN        0.429602  ['ARQ2PMX1187FB38D62' 'ARHNL9K1187FB5730C' 'AR...     ['mandarin' 'cantonese' 'hong kong' 'chinese']        5\n",
        "1  SOXJOMM12A6D4F8673  ARF1E421187B9AF8C4  Alma de B-Boy      0.511424             0  208.66567    -7.705     0                 22050            0      Comunicaflow Underground  [ 0.071  0.037  0.056  0.171  0.022  0.048  0....    0     1            0.559  120.064            El Gran Silencio                       NaN        0.375494  ['AR5U53D1187FB37654' 'ARCW1I81187FB41D5D' 'AR...                                                 []        2\n",
        "2  SOJGTKX12AB0188C94  ARQ76LG1187B9ACD84  Jealous Again           NaN             0  136.14975    -6.419  1980                 22050            0  Live at The On Broadway 1982  [ 0.195  0.169  0.113  0.081  0.187  0.411  0....    4     1            0.553  124.481                  Black Flag           Los Angeles, CA        0.547507  ['AR7Y6JX1187FB4D9B3' 'ARCC31M1187B9ACB05' 'AR...  ['hardcore punk' 'california' 'hermosa beach' ...        3\n",
        "3  SOSQCCK12AB0186B7C  AR7LN7G1187FB395BB     \u00c0 Mon Avis      0.352232             0  431.93424    -6.451     0                 22050            0                  Bakolo Mboka  [ 0.099  0.001  0.083  0.021  0.076  0.085  0....    7     0            0.131  134.046  Les Bantous De La Capitale                       NaN        0.273366  ['ARXK8H71187FB44850' 'ARNMVXP11F50C4BAFF' 'AR...                                                 []        4\n",
        "4  SOQXTRG12A6D4F898E  AR3N2H11187B98AFBA        Energia           NaN             0  238.00118   -10.623     0                 22050            0               Selecao De Ouro  [ 0.133  0.389  0.205  0.106  0.081  0.172  0....    5     0            0.187  224.247                      Sivuca  Itabaiana, Para\ufffd, Brazil        0.324334  ['ARI4RPW1187B9B862D' 'ARQCHDN1187FB4C7C2' 'AR...                                                 []        4"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### TODO clean up the data\n",
      "\n",
      "\"\"\"a = hi[hi.Duration == 208.66567].Tags.values[0] \n",
      "print a\"\"\"\n",
      "\n",
      "data_df.Song_Hotness = data_df.Song_Hotness.replace(0, np.nan) # eliminate all empty tags\n",
      "#print hi[hi.Duration == 208.66567].Danceability\n",
      "\n",
      "hi = data_df.dropna()\n",
      "hi.head(5)\n",
      "\n",
      "### do some more data clean up\n",
      "print len(filter(lambda x: x == 0, hi.Song_Hotness.values))\n",
      "print len(hi.Song_Hotness.values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "154\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# gather music lyrics for all the popular songs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clean_df = hi ## replace with whatever we get\n",
      "\n",
      "\n",
      "### exploratory visualizations\n",
      "def scatter_regress(data1, data2, title=\"\"):\n",
      "    np.polyfit(data1, data2, 2) \n",
      "\n",
      "    plt.scatter(data1, data2)\n",
      "    remove_border()\n",
      "\n",
      "    fit = polyfit(data1, data2,1)\n",
      "    fit_fn = poly1d(fit)\n",
      "    plot(data1,data2, 'yo', data1, fit_fn(data1), '--k')\n",
      "    plt.title(title)\n",
      "    plt.show()\n",
      "\n",
      "### do the same thing for rating with like every category\n",
      "scatter_regress(clean_df.Loudness.values, clean_df.Duration.values, \"Loudness vs Duration\")\n",
      "\n",
      "## TODO figure out how to embed this in the notebook\n",
      "grouped_by_hotness = clean_df.groupby(clean_df.Song_Hotness)\n",
      "gg = pd.Series(clean_df.Song_Hotness, clean_df.Ratings)\n",
      "#plt.hist(gg)\n",
      "#scatter_regress(clean_df.Song_Hotness, clean_df.Ratings, \"Ratings and Song Hotness\")\n",
      "\n",
      "### Ratings is a categorical variable at this point\n",
      "scatter_regress(clean_df.Ratings.values, clean_df.Song_Hotness, \"Ratings and Song Hotness\")\n",
      "\n",
      "\"\"\"scatter_regress(clean_df.Ratings.values, clean_df.Song_Hotness, \"Ratings and Song Hotness\")\n",
      "scatter_regress(clean_df.Ratings.values, clean_df.Song_Hotness, \"Ratings and Song Hotness\")\n",
      "scatter_regress(clean_df.Ratings.values, clean_df.Song_Hotness, \"Ratings and Song Hotness\")\n",
      "\n",
      "# grouped by\n",
      "grouped_by_year = clean_df.groupby(clean_df.Year)\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'hi' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-2-d4e1bcb9aca2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhi\u001b[0m \u001b[0;31m## replace with whatever we get\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m### exploratory visualizations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscatter_regress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'hi' is not defined"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# average song rating in this data set\n",
      "print \"Average rating of songs in the data set: \" + str(clean_df.Ratings.mean())\n",
      "star_count = clean_df.groupby('Ratings')\n",
      "plt.hist(clean_df.Ratings, bins=[1,2,3,4,5,6], align='left')\n",
      "plt.title(\"Rating distribution of songs in the data set\")\n",
      "remove_border()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Average rating of songs in the data set: 3.02359882006\n"
       ]
      }
     ],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### compute some category averages\n",
      "def recompute_frame(ldf):\n",
      "    \"\"\"\n",
      "    takes a dataframe ldf, makes a copy of it, and returns the copy\n",
      "    with all averages and review counts recomputed\n",
      "    this is used when a frame is subsetted.\n",
      "    \"\"\"\n",
      "    \n",
      "    ### can do it by artist and by album\n",
      "    ldfu=ldf.groupby('Artist_ID')\n",
      "    ldfb=ldf.groupby('Album_Name')\n",
      "    \n",
      "    artist_avg=ldfu.Ratings.mean()\n",
      "    \n",
      "    artist_song_count=ldfu.Song_ID.count()\n",
      "    \n",
      "    album_avg=ldfb.Ratings.mean()\n",
      "    album_song_count=ldfb.Song_ID.count()\n",
      "    \n",
      "    nldf=ldf.copy()\n",
      "    nldf.set_index(['Artist_ID'], inplace=True)\n",
      "    nldf['Artist_avg']=artist_avg\n",
      "    nldf['Artist_Song_count']=artist_song_count\n",
      "    \n",
      "    nldf.reset_index(inplace=True)\n",
      "    nldf.set_index(['Album_Name'], inplace=True)\n",
      "    nldf['Album_avg']=album_avg\n",
      "    nldf['Album_Song_count']=album_song_count\n",
      "    nldf.reset_index(inplace=True)\n",
      "    return nldf\n",
      "    \n",
      "print \"Unique songs: \" + str(len(clean_df.Song_ID.unique()))\n",
      "print \"Unique artists: \" + str(len(clean_df.Artist_ID.unique()))\n",
      "\n",
      "full_df = recompute_frame(clean_df)\n",
      "full_df.head(10)\n",
      "\n",
      "##### we might want to filter out the artists or albums that are too sparse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'clean_df' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-61987f03311d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnldf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Unique songs: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSong_ID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Unique artists: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtist_ID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'clean_df' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us identify which variables are significant using the Spearman coefficient. Here is a little bit about it, which speaks to why we decided to use it:\n",
      "The Spearman correlation is a nonparametric measure of the linear relationship between two datasets. Unlike the Pearson correlation, the Spearman correlation does not assume that both datasets are normally distributed. Like other correlation coefficients, this one varies between -1 and +1 with 0 implying no correlation. Correlations of -1 or +1 imply an exact linear relationship. Positive correlations imply that as x increases, so does y. Negative correlations imply that as x increases, y decreases.\n",
      "\n",
      "The p-value roughly indicates the probability of an uncorrelated system producing datasets that have a Spearman correlation at least as extreme as the one computed from these datasets. The p-values are not entirely reliable but are probably reasonable for datasets larger than 500 or so."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### use spearman coefficients to compute\n",
      "print \"Relationship between ratings and song hotness: \"stats.spearmanr(clean_df.Ratings.values, clean_df.Song_Hotness)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(-0.058903462275063705, 0.46805481115548664)\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's us build up a model incorporating the quantitative variables:\n",
      "(http://wiki.scipy.org/Cookbook/OLS)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# OLS (ordinary least squares) on quant variables\n",
      "\n",
      "### use real variables here\n",
      "import ols\n",
      "from numpy.random import randn\n",
      "data = randn(100,5)\n",
      "y = data[:,0]\n",
      "x = data[:,1:]\n",
      "mymodel = ols.ols(y,x,'y',['x1','x2','x3','x4'])\n",
      "print mymodel.p               # return coefficient p-values\n",
      "\n",
      "mymodel.summary()       # print results\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.36419649  0.47826698  0.30301987  0.61140604  0.01806257]\n",
        "\n",
        "==============================================================================\n",
        "Dependent Variable: y\n",
        "Method: Least Squares\n",
        "Date:  Mon, 09 Dec 2013\n",
        "Time:  13:15:34\n",
        "# obs:                 100\n",
        "# variables:         5\n",
        "==============================================================================\n",
        "variable     coefficient     std. Error      t-statistic     prob.\n",
        "==============================================================================\n",
        "const          -0.100144      0.109834     -0.911772      0.364196\n",
        "x1             -0.075410      0.105927     -0.711907      0.478267\n",
        "x2              0.104719      0.101120      1.035595      0.303020\n",
        "x3             -0.052631      0.103248     -0.509754      0.611406\n",
        "x4             -0.257122      0.106866     -2.406023      0.018063\n",
        "==============================================================================\n",
        "Models stats                         Residual stats\n",
        "==============================================================================\n",
        "R-squared             0.070989         Durbin-Watson stat   2.004026\n",
        "Adjusted R-squared    0.031873         Omnibus stat         2.856692\n",
        "F-statistic           1.814817         Prob(Omnibus stat)   0.239705\n",
        "Prob (F-statistic)    0.132334\t\t\tJB stat              2.621272\n",
        "Log likelihood       -143.177544\t\t\tProb(JB)             0.269648\n",
        "AIC criterion         2.963551         Skew                -0.313060\n",
        "BIC criterion         3.093809         Kurtosis             2.513092\n",
        "==============================================================================\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "*css tweaks in this cell*\n",
      "<style>\n",
      "div.text_cell_render {\n",
      "    line-height: 150%;\n",
      "    font-size: 110%;\n",
      "    width: 800px;\n",
      "    margin-left:50px;\n",
      "    margin-right:auto;\n",
      "    }\n",
      "</style>"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}